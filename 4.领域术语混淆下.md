# 三、嵌入构建与向量化阶段（Embedding & Vectorization）
核心任务：将经过清洗和标准化的术语，转化为机器可理解的密集向量（Dense Vectors），并构建高效的检索索引。这直接决定了系统语义匹配的能力上限。


### 技术详情表
| 技术名称                          | 描述                                   | 对术语一致性的帮助               |
|-----------------------------------|----------------------------------------|----------------------------------|
| 术语嵌入与向量索引（FAISS / Pinecone） | 将术语及其别名转换为向量并构建索引     | 支持语义匹配，提升检索时的术语识别能力 |
| 域专用嵌入模型（Legal-BERT、ChatLaw-Text2Vec） | 在专业语料上继续训练通用模型           | 提升术语理解质量，增强语义表示     |
| Sentence Transformers + PEFT（LoRA）微调 | 参数高效微调嵌入模型                   | 针对特定领域进一步优化术语语义表示 |


### 步骤二：2.2 基于向量相似度的同义词发现
```python
from sentence_transformers import SentenceTransformer, util

# 建议在项目初始化时加载模型，避免重复加载
# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

def map_synonyms_by_similarity(main_terms: list, candidates: list, threshold: float = 0.8) -> dict:
    """
    通过计算向量余弦相似度，将候选词映射到最接近的标准术语。
    
    Args:
        main_terms (list): 标准术语列表。
        candidates (list): 待匹配的候选同义词列表。
        threshold (float): 判断为同义词的相似度阈值。
    """
```

### 基于向量相似度的同义词发现（完整代码）
```python
def map_synonyms_by_similarity(main_terms: list, candidates: list, threshold: float = 0.8) -> dict:
    """
    通过计算向量余弦相似度，将候选词映射到最接近的标准术语。
    
    Args:
        main_terms (list): 标准术语列表。
        candidates (list): 待匹配的候选同义词列表。
        threshold (float): 判断为同义词的相似度阈值。
    """
    # 初始化：为每个标准术语创建空列表存储匹配的同义词
    matched_synonyms = {term: [] for term in main_terms}
    
    if not main_terms or not candidates:
        return matched_synonyms
    
    # 批量编码以提升效率
    embeddings = model.encode(main_terms + candidates, convert_to_tensor=True)
    term_embeddings = embeddings[:len(main_terms)]
    candidate_embeddings = embeddings[len(main_terms):]
    
    # 计算标准术语与所有候选词的余弦相似度矩阵
    similarity_matrix = util.cos_sim(term_embeddings, candidate_embeddings)
    
    # 遍历相似度矩阵，匹配符合阈值的候选词
    for i, term in enumerate(main_terms):
        for j, candidate in enumerate(candidates):
            if similarity_matrix[i][j] > threshold:
                matched_synonyms[term].append(candidate)
    
    return matched_synonyms


# 示例：
main_terms_to_map = ["卷积神经网络", "神经网络"]
all_possible_synonyms = ["CNN", "ConvNet", "人工神经网络", "NN", "神经系统", "深度学习模型"]

optimized_mapped_synonyms = map_synonyms_by_similarity(main_terms_to_map, all_possible_synonyms)
print("\n优化后匹配的别名：", optimized_mapped_synonyms)
```

```
import os

# 定义你的代理地址
proxy_url = 'http://127.0.0.1:4780'

# 为HTTP和HTTPS流量设置代理
# 大多数模型下载操作都通过HTTPS，所以“HTTPS_PROXY”至关重要
os.environ['HTTP_PROXY'] = proxy_url
os.environ['HTTPS_PROXY'] = proxy_url

print("代理环境变量已设置。")
print(f"HTTP_PROXY: {os.getenv('HTTP_PROXY')}")
print(f"HTTPS_PROXY: {os.getenv('HTTPS_PROXY')}")


# --- 在这里开始你的正常代码 ---
# 例如，现在加载模型，它将通过指定的代理进行下载
from sentence_transformers import SentenceTransformer

# 只有在模型未被缓存时，才会通过代理下载
model_name = 'paraphrase-multilingual-MiniLM-L12-v2'
print(f"\n正在尝试加载模型 '{model_name}'...")
try:
    model = SentenceTransformer(model_name)
    print("模型加载/下载成功！")
except:
    # 注：代码中未写except分支的具体处理逻辑
    pass
```


```
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

def build_term_vector_index(term_glossary: dict, model: SentenceTransformer) -> tuple:
    """
    将术语词库中的所有术语及其别名转换为向量，并构建FAISS索引。
    
    Args:
        term_glossary (dict): 结构化的术语词库。键为标准术语，值为包含'synonyms'列表的字典。
        model (SentenceTransformer): 已加载的SentenceTransformer模型实例。
        
    Returns:
        tuple: (faiss.Index, list) 返回构建好的FAISS索引对象和与之对应的术语列表。
    """
    terms_to_index = []
    # 修正点：将 term_mapping_dict 修改为 term_glossary
for standard_term, info in term_glossary.items():
    terms_to_index.append(standard_term)
    if "synonyms" in info and isinstance(info["synonyms"], list):
        terms_to_index.extend(info["synonyms"])

unique_terms_to_index = sorted(list(set(terms_to_index)))

print("正在生成术语向量...")
embeddings = model.encode(unique_terms_to_index, show_progress_bar=True)

# 转换向量类型为FAISS要求的float32
embeddings = embeddings.astype('float32')
dimension = embeddings.shape[1]

# 构建FAISS的L2距离索引
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

print(f"FAISS索引构建完成。包含 {index.ntotal} 个向量，维度为 {dimension}。")
return index, unique_terms_to_index


# 示例：调用函数构建索引
# 1. 加载模型
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# 2. 准备术语数据
term_mapping_example = {
    "卷积神经网络": {"synonyms": ["CNN", "ConvNet"]},
    "Transformer": {"synonyms": ["transformer", "TRANSFORMER"]},
    "图像识别": {"synonyms": ["图像分类", "视觉识别"]}
}
```

<img width="290" height="323" alt="image" src="https://github.com/user-attachments/assets/e11cf6b0-140b-4eb7-8413-bfc66adb408f" />

```
# --- 第2部分：定义我们的核心检索函数 ---
def search_similar_terms(query_text: str, model: SentenceTransformer, index: faiss.Index, term_list: list, k: int = 5):
    """
    在FAISS索引中检索与查询文本最相似的k个术语。
    
    Args:
        query_text (str): 用户输入的查询词。
        model (SentenceTransformer): 用于编码查询词的模型。
        index (faiss.Index): FAISS索引对象。
        term_list (list): 与索引向量顺序一致的术语列表。
        k (int): 希望返回的最相似结果的数量。
    """
    print(f"\n--- 正在执行检索 ---")
    print(f"查询：{query_text}")
    
    # 1. 将查询文本编码为向量
    query_vector = model.encode([query_text])
    query_vector = query_vector.astype('float32')
    
    # 2. 在FAISS索引中执行搜索
    # index.search返回两个数组：D（distances，距离）和 I（indices，索引）
    distances, indices = index.search(query_vector, k)
    
    # 3. 解析并打印结果
    print("检索结果:")
    for i in range(k):
        idx = indices[0][i]
        # 注：代码中未完成结果打印的完整逻辑（如匹配术语、输出距离）
```
# 四、检索增强阶段
核心目标：在初步召回（Recall）的基础上，进一步优化检索结果的广度与精度。预处理阶段解决了术语的“标准”问题，而本阶段则聚焦于如何利用这些标准化的知识，在实际检索中发挥最大效用。


### 技术详情表
| 技术名称                          | 描述                                                                 | 对术语一致性的帮助                                                         |
|-----------------------------------|----------------------------------------------------------------------|--------------------------------------------------------------------------|
| 查询扩展与重写（MultiQueryRetriever） | 利用LLM生成多个语义等价的查询变体，合并检索结果。                     | 自动覆盖用户未提及的同义词或相关表达，极大提升对多样化术语的识别与召回能力。 |
| HyDE（假设文档嵌入）| 利用LLM为查询生成一个“理想答案”的假设性文档，再用该文档的嵌入进行检索。 | 通过生成富含上下文的理想答案，有效缓解原始查询中术语模糊或信息不足的问题，提升检索相关性。 |
| 混合检索（BM25 + FAISS）| 结合关键词检索（如BM25）与向量检索（如FAISS）的优势。                  | 综合利用字面精确匹配和语义相似匹配，确保基础术语不丢失，同时发现语义相关内容。 |
| 交叉编码器重排序（BGE-reranker）| 使用更复杂的交叉编码器模型（如BGE-reranker）对召回结果进行精细化重排序。 | 通过深度交互分析查询与文档的匹配度，提升对术语匹配度的排序精度。|


### 依赖安装命令
```bash
!pip install langchain_community
!pip install langchain langchain-openai faiss-cpu sentence-transformers
```

# 五、生成控制与输出验证阶段


### 技术详情表
| 技术名称                  | 描述                                                                 | 对术语一致性的贡献与作用                                                 |
|---------------------------|----------------------------------------------------------------------|--------------------------------------------------------------------------|
| 提示工程 (Prompt Engineering) | 在提示中明确指令，引导 LLM 使用标准术语、保持特定风格。| 最基础的控制手段，直接影响 LLM 的选词倾向，引导其遵循术语规范。|
| 结构化输出 (Structured Output) | 强制 LLM 返回符合预定义模式（如 Pydantic 或 JSON Schema）的对象。| 从根本上杜绝术语的随意使用，确保关键信息以标准、可控的格式输出。|
| 输出解析与修复 (Output Parsers) | 使用如 OutputFixingParser 等工具，在 LLM 输出格式错误时自动尝试修复。 | 提升结构化输出的鲁棒性，能自动纠正轻微的术语格式或拼写错误。|
| 后处理与内容增强          | 在答案文本中自动高亮术语、添加定义弹窗或引用链接。| 提升最终答案的可读性和专业性，为用户提供即时的术语解释和来源追溯。|
| LLM即评委 (LLM-as-a-Judge) | 使用另一个 LLM 实例，根据预设标准（如术语一致性）对生成结果进行打分评估。 | 提供一种可扩展的、自动化的输出质量与术语合规性评估方案。|



# 总结：术语一致性优化路线图
经过以上各阶段的详细探讨，从数据预处理到最终的评估反馈，我们已经全面构建了保障术语一致性的技术体系。
为了更直观地理解各项技术的定位与优先级，我们将整个优化策略总结为以下分级路线图，为不同阶段的RAG系统建设提供实践指引。


### 术语一致性优化分级路线图
| 优化层级               | 核心技术与解决方案                                           |
|------------------------|--------------------------------------------------------------|
| 基础核心（Foundation） | 术语词库构建、术语抽取、预处理标准化、术语嵌入与向量索引       |
| 关键增强（Key Enhancement） | 混合检索（BM25 + 向量）、查询扩展（MultiQuery）、假设性文档嵌入（HyDE）、交叉编码器重排序 |
| 辅助优化（Auxiliary Optimization） | 领域专用嵌入模型微调、上下文感知分块                         |
| 生成控制（Generation Control） | 提示工程、结构化输出、输出解析与修复                         |
| 长期保障（Long-term Assurance） | LLM即评委（LLM-as-a-Judge）、用户反馈闭环、日志审计与分析     |

















